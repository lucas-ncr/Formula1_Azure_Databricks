# ğŸï¸ Formula 1 Data Engineering Project on Azure Databricks

ğŸ“… **Period:** March 2025 - April 2025  
ğŸŒ **Location:** SÃ£o Paulo, Brazil  
ğŸ”§ **Technologies:** Databricks, Azure, Apache Spark, PySpark, SQL, Delta Lake, Data Factory, Power BI, Unity Catalog

---

## ğŸš€ Project Overview

This project applies **cloud data engineering best practices** using real-world **Formula 1 data from 1950 onwards**, leveraging tools from the Azure ecosystem and Apache Spark.

Throughout the project, we developed the core skills required for the **Azure Data Engineer Associate (DP-203)** certification, focusing on governance, ingestion, transformation, analysis, and visualization.

---

## ğŸ§  Skills Acquired

- âœ… Data ingestion and transformation with **PySpark**
- âœ… Querying and analysis using **Spark SQL**
- âœ… Dimensional modeling with **Star Schema**
- âœ… Efficient storage with **Data Lake Gen2** and **Delta Lake**
- âœ… Orchestration with **Azure Data Factory (ADF)**
- âœ… Data governance using **Unity Catalog, Azure Key Vault, and Azure AD**
- âœ… Dashboards and reporting with **Databricks and Power BI**
- âœ… Modern architectures: **Data Lake** & **Lakehouse**

---

## ğŸ§° Tools & Technologies Used

| Technology             | Main Role                                           |
|------------------------|-----------------------------------------------------|
| **Azure Databricks**   | Notebooks, job scheduling, dashboards               |
| **Apache Spark / PySpark** | Distributed data processing and transformation |
| **Delta Lake**         | Optimized storage with incremental updates          |
| **Azure Data Lake Gen2** | Data lake for raw and processed data               |
| **Azure Data Factory** | Orchestration and automation of data pipelines      |
| **Power BI**           | Reporting and visualization                         |
| **Unity Catalog**      | Governance and centralized data catalog             |
| **Azure Key Vault**    | Secure credential and secret management             |
| **Azure Active Directory** | User authentication and access control         |

---

## ğŸ§© Solution Architecture

```
                     +-------------------------+
                     |   Azure Data Factory    |
                     |   (Orchestration Layer) |
                     +-----------+-------------+
                                 |
          +----------------------+-------------------------+
          |                                                |
          â–¼                                                â–¼
 +-----------------------+                 +------------------------------+
 | Trigger Databricks    |                 | Monitor & Manage Pipelines  |
 | Jobs via ADF Pipelines|                 | and Schedule Increments     |
 +----------+------------+                 +-------------+----------------+
            |                                               
            â–¼                                                                    
+----------------------------+                         
|      Azure Databricks      |  â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†  
| (Notebooks: PySpark & SQL) |        Development, ELT & Data Analysis  
+----------------------------+                         
            |                                         
            â–¼                                         
    +---------------+
    |  Bronze Data  |
    |   Container   |
    |  (Delta Lake) |
    +---------------+
            |
            |
            â–¼
    +---------------+
    |  Silver Data  |
    |   Container   |
    |  (Delta Lake) |
    +---------------+
            |
            |
            â–¼
    +---------------+
    |   Gold Data   |
    |   Container   |
    |  (Delta Lake) |
    +---------------+
            |
            |
            â–¼                                      
    +---------------------+                           
    |    Power BI / BI    |  â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†  
    | Dashboards & Reports|     Data Visualizations & Insights   
    +---------------------+
```

---

## ğŸ› ï¸ Project Execution Steps

### 1. ğŸ”§ Environment Setup
- Created **Databricks clusters**, **notebooks**, **dashboards**, and **jobs**
- Integrated with **Azure Data Lake Gen2**
- Configured **Unity Catalog**, **Azure AD**, and **Azure Key Vault** for secure access and governance

### 2. ğŸ“¥ Data Ingestion
- Collected historical Formula 1 data (CSV/JSON format)
- Ingested raw data into the **Bronze layer** using PySpark in Databricks

### 3. ğŸ”„ Data Transformation & Modeling
- Transformed and cleaned data using PySpark
- Stored processed data in **Delta tables** in **Silver** and **Gold** layers
- Implemented **partitioning** and **incremental load** techniques for performance

### 4. ğŸ§ª Data Analysis with Spark SQL
- Created **external tables** and **temporary views**
- Performed analysis using Spark SQL on races, drivers, teams, and standings

### 5. ğŸ“Š Data Visualization
- Published **interactive dashboards in Databricks**
- Connected **Power BI** to Databricks for advanced reporting and sharing

### 6. ğŸ“† Pipeline Orchestration with ADF
- Built **ADF pipelines** to trigger Databricks notebooks
- Implemented **triggers and monitoring** for weekly updates with alerts

### 7. ğŸ” Data Governance
- Configured **Unity Catalog** to manage metadata and access policies
- Applied **role-based access controls** using Azure AD
- Used **Key Vault** for secure secret management

---

## ğŸ“‰ Results Achieved

- ğŸ”„ **87% reduction** in pipeline processing time with incremental loading  
- ğŸ“Š Full analytical coverage of Formula 1 history from 1950 onward  
- âœ… Modern **Lakehouse architecture** implementation  
- ğŸ” Strong data governance using best practices and Azure-native tools

---

## ğŸ§‘â€ğŸ’» Ideal For

âœ”ï¸ Data engineering professionals working with **Azure Databricks**  
âœ”ï¸ Individuals preparing for the **DP-203 Azure Certification**  
âœ”ï¸ Anyone looking to build a **real-world, end-to-end data pipeline**

---

## ğŸ“ Prerequisites

- Azure subscription with access to **Databricks**, **Data Lake Gen2**, and **Data Factory**  
- **Power BI Desktop** (optional, for local visualization)  
- Basic knowledge of **Python, SQL, and Spark**

---

## ğŸ Final Thoughts

This project demonstrates how to **design, manage, and orchestrate cloud data pipelines** from raw ingestion to final dashboardsâ€”using real, rich historical Formula 1 data. It's a powerful example of combining engineering, analytics, and governance in a real-world scenario.
